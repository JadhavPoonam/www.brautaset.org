<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2017-06-07 Wed 16:22 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>A Lesson in Benchmarking</title>
<meta name="generator" content="Org mode">
<meta name="author" content="Stig Brautaset">
<link rel="stylesheet" type="text/css" href="/css/main.css" />
      <link rel="icon" type="image/png" href="/images/icon.png" />
<script type="text/javascript">
if(/superloopy.io/.test(window.location.hostname)) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-4113456-6', 'auto');
  ga('send', 'pageview');
}
</script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2017 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>

<div id="org-div-home-and-up">
  <img src="/images/logo.png" alt="Superloopy Logo"/>
  <nav>
    <ul>
      <!-- <li><a accesskey="h" href="/"> Up </a></li>
 -->
      <li><a accesskey="H" href="/"> Home </a></li>
      <li><a accesskey="a" href="/articles"> Articles </a></li>
      <li><a accesskey="p" href="/publications.html"> Publications </a></li>
      <li><a accesskey="A" href="/about.html"> About </a></li>
    </ul>
  </nav>
</div>
<div id="content">
<h1 class="title">A Lesson in Benchmarking</h1>
<p>
Our API had a cache builder abstraction that allowed us to use either an
in-memory LRU cache or memcached. The LRU cache was faster, but the
memcached version could be shared, and "unlimited" in size. It was added
on the theory that as we scaled out, the memcached version would be
better because a higher number of instances would see fewer cache hits.
</p>

<p>
The Memcached version was never really used in anger: it was too slow
for the hottest caches, and we had a brief outage due to a missed
<code>@SerialVersionUID</code> annotation on some code&#x2013;which manifest itself at
deployment, when the old version of the code wrote a version of the
serialised class to the cache and the new version tried to instanciate
this. Coupled with the need to manage more machines meant that we moved
away from using it when we moved our API to AWS. Finally it was a lot of
code (about 10% of this particular project's code base!) so recently I
removed the abstraction layer and the memcache version, leaving only the
LRU version.
</p>

<p>
Just for curiosity I did a load test before and after, on otherwise
identical setup. The load test consist of replaying access logs from a
few weeks back. I expected no change, or if anything a small improvement
in performance. Instead I was gobsmacked to see see a 25% increase in
throughput, sustained over 50 minutes. I thought there must be a
mistake. The API serves product data for a retail site, and the baseline
was the previous commit&#x2014;but the baseline was run the day before our
sale ended. It occured to me that that because I ran the new test the
day <i>after</i> the sale ended, a lot of requests would return 0-length
responses, which would be served faster. This explained everything!
<i>Except</i> that the environment where I ran the load test had a static
data dump, so its data hadn't changed. Damn!
</p>

<p>
So I redid the test, for both the baseline and my change, but this time
replaying access logs from <i>after</i> the sale ended to be more
representative. This time we saw a <i>50%</i> increase in throughput. Best
part: 99th percentile improvements in latency from 1.3s to 540ms! Worst
part: not understanding how, or why. I was now questioning everything,
including my sanity.
</p>

<p>
Looking deeper into the metrics for the wider stack it turns out that we
fired fewer requests to data stores behind the API layer. This implies
that our API-layer cache is more effective after the change. I was
confident that the change didn't introduce unintend change of behaviour.
We strongly suspected a bug somewhere in all the code that was deleted
that caused the caching to be not as efficient as it should have been.
Since it was an unexpected <i>increase</i> in performance I decided not to
waste more time trying to explain exactly why.
</p>

<p>
The change went into production, where we regretfully didn't see the
improvement on our latency we saw during our load test. However, we
<i>did</i> see a reduced number of queries against the backend for the same
load on the frontend. We thought the reason we were not seing an
improvement in latency was that our live environment was not as stressed
as our load testing environment, so it was <i>already</i> at the lower tier
of latency. In other words, it would take more pounding before latency
degraded.
</p>

<p>
A few days later&#x2014;during load testing of an unrelated change&#x2014;we found
the <i>actual</i> reason for the speedup: Since there was only one cache
implementation left I renamed a config key from <code>foo.cache.lru-max-size</code>
and <code>foo.cache.memcache-max-size</code> to simply <code>foo.cache.max-size</code>. This
was not overriden in our test &amp; production environments and therefore
ended up using the (far too large) default value. We found this when the
feature we were testing put so many objects in the cache that the JVM
ran out of memory and started throwing exceptions&#x2026;
</p>

<p>
Moral of the story: <i>be suspicious of accidental performance gains</i>.
Luckily we caught this before we had a production outage, but I should
have trusted my initial instinct and looked harder to find the cause for
the unexpected speedup. I'll know next time!
</p>
</div>
<div id="postamble" class="status">
<p class="date">Date: 2015-02-24</p>
<p class="author">Author: Stig Brautaset</p>
<p class="date">Created: 2017-06-07 Wed 16:22</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
